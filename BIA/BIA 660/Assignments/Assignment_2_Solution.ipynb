{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define a function to analyze a numpy array (5 points)\n",
    " - Assume we have an array (with shape (M,N)) which contains term frequency of each document, where each row is a document, each column is a word, and the corresponding value denotes the frequency of the word in the document. Define a function named \"analyze_tf_idf\" which: (overall 1 point)\n",
    "      * takes the **array**, and an integer **K** as the parameters.\n",
    "      * normalizes the frequency of each word as: word frequency divided by the length of the document. Save the result as an array named **tf** (i.e. term frequency) (1 point)\n",
    "      * calculates the document frequency (**df**) of each word, e.g. how many documents contain a specific word (1 point)\n",
    "      * calculates **tf_idf** array as: **tf / (log(df)+1)** (tf divided by log(df)). The reason is, if a word appears in most documents, it does not have the discriminative power and often is called a \"stop\" word. The inverse of df can downgrade the weight of such words. (1 point)\n",
    "      * for each document, finds out the **indexes of words with top K largest values in the tf_idf array**, ($0<K<=N$). These indexes form an array, say **top_K**, with shape (M, K) (1 point)\n",
    "      * returns the tf_idf array, and the top_K array. \n",
    " - Note, for all the steps, ** do not use any loop**. Just use array functions and broadcasting for high performance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a function to analyze stackoverflow dataset using pandas (5 points)\n",
    " - Define a function named \"analyze_data\" to do the follows:\n",
    "   * Take a csv file path string as an input. Assume the csv file is in the format of the provided sample file (question.csv).\n",
    "   * Read the csv file as a dataframe with the first row as column names\n",
    "   * Find questions with top 3 viewcounts among those answered questions (i.e answercount>0). Print the title and viewcount columns of these questions. (1 point)\n",
    "   * Find the top 5 users (i.e. quest_name) who asked the most questions. (1 point)\n",
    "   * Create a new column called \"first_tag\" to store the very first tag in the \"tags\" column (hint: use \"apply\" function; tags are separted by \", \") (1 point)\n",
    "   * Show the mean, min, and max viewcount values for each of these tags: \"python\", \"pandas\" and \"dataframe\" (1 point)\n",
    "   * Create a cross tab with answercount as row indexes, first_tag as column names, and the count of samples as the value. For \"python\" question (i.e. first_tag=\"python\"), how many questions were not answered (i.e., answercount=0), how many questions were answered once (i.e., answercount=1), and how many questions were anasered twice  (i.e., answercount=2)? Print these numbers. (1 point)\n",
    " - This function does not have any return. Just print out the result of each calculation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (Bonus). Analyzed a collection of documents (3 points)\n",
    " - Define a function named \"analyze_corpus\" to do the follows:\n",
    "   * Similar to Q2, take a csv file path string as an input. Assume the csv file is in the format of the provided sample file (question.csv).\n",
    "   * Read the \"title\" column from the csv file and convert it to lower case\n",
    "   * Split each string in the \"title\" column by space to get tokens. Create an array where each row represents a title, each column denotes a unique token, and each value denotes the count of the token in the document (2 points)\n",
    "   * Call your function in Q1 (i.e. analyze_tf_idf) to analyze this array\n",
    "   * Print out the top 5 words by tf-idf score for the first 20 questions. Do you think these top words allow you to find similar questions or differentiate a question from dissimilar ones? Write your analysis as a pdf file. (1 point)\n",
    "   \n",
    "- This function does not have any return. Just print out the result if asked.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Guideline##\n",
    "- Following the solution template provided below. Use __main__ block to test your functions\n",
    "- Save your code into a python file (e.g. assign2.py) that can be run in a python 3 environment. In Jupyter Notebook, you can export notebook as .py file in menu \"File->Download as\".\n",
    "- Make sure you have all import statements. To test your code, open a command window in your current python working folder, type \"python assign2.py\" to see if it can run successfully.\n",
    "- **Each homework assignment should be completed independently. Never ever copy others' work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q1\n",
      "[[3 1 5]\n",
      " [4 0 3]\n",
      " [2 5 4]]\n",
      "\n",
      "Q2\n",
      "           id         creationdate  score  viewcount  \\\n",
      "75   48066517  2018-01-02 19:12:03     24      33297   \n",
      "163  48094854  2018-01-04 12:01:18      3      16658   \n",
      "886  48350850  2018-01-19 23:12:38      3      11176   \n",
      "\n",
      "                                                 title  answercount  \\\n",
      "75   Python: Pandas pd.read_excel giving ImportErro...            7   \n",
      "163                     Python convert object to float            2   \n",
      "886                  Subtract two columns in dataframe            5   \n",
      "\n",
      "                                  tags        quest_name  \n",
      "75   python, excel, python-2.7, pandas       Vineeth Sai  \n",
      "163                     python, pandas  Almog Woldenberg  \n",
      "886                     python, pandas             Peter  \n",
      "Shuvayan Das    7\n",
      "Rahul rajan     7\n",
      "el323           6\n",
      "Danny W         6\n",
      "Hana            5\n",
      "Name: quest_name, dtype: int64\n",
      "           amin   amax        mean\n",
      "first_tag                         \n",
      "pandas       14   4499  454.687500\n",
      "python        5  33297  428.670091\n",
      "answercount\n",
      "0     98\n",
      "1    455\n",
      "2    232\n",
      "3     64\n",
      "Name: python, dtype: int64\n",
      "None\n",
      "\n",
      "Q3\n",
      "('Array in Pandas Dataframe', ['array', 'dataframe', 'in', 'pandas', 'strings'])\n",
      "('Pandas manual label encoding', ['manual', 'label', 'encoding', 'pandas', 'identifying'])\n",
      "('Write Pandas Dataframe to CSV with a variable name in pathway', ['pathway', 'variable', 'write', 'name', 'csv'])\n",
      "('Adding a time index to a pandas dataframe from google finance', ['google', 'finance', 'adding', 'a', 'time'])\n",
      "('How to convert values of a pandas data frame column to a numeric representation based on the number of unique values, all at once in Python?', ['representation', 'once', 'values,', 'numeric', 'of'])\n",
      "('create a dictionary in python from columns of a dataframe', ['a', 'dictionary', 'create', 'columns', 'from'])\n",
      "('pandas clever way of setting columns under conditions', ['under', 'setting', 'clever', 'conditions', 'way'])\n",
      "('Pandas misinterpreting date column in CSV file', ['misinterpreting', 'date', 'csv', 'file', 'column'])\n",
      "('Summing up values across multiple columns into groups which are defined in a dictionary', ['defined', 'summing', 'across', 'up', 'are'])\n",
      "('LabVIEW TDMS file read with python pandas', ['labview', 'tdms', 'read', 'file', 'python'])\n",
      "('Rewrite NLTK code to a function which can be used multiple times in Python', ['rewrite', 'used', 'nltk', 'times', 'be'])\n",
      "('Formatting dataframe output into JSON records by group', ['formatting', 'records', 'json', 'output', 'group'])\n",
      "('NLTK-based text processing with pandas', ['processing', 'nltk-based', 'text', 'with', 'pandas'])\n",
      "('Calculating percentile of each device_id in a particular column', ['device_id', 'calculating', 'percentile', 'particular', 'each'])\n",
      "('Transform pandas dataframe to another layout', ['layout', 'transform', 'another', 'dataframe', 'to'])\n",
      "('Vectorized operations on 2 columns of different dataframes', ['vectorized', 'operations', '2', 'different', 'dataframes'])\n",
      "('Select python data-frame columns with similar names', ['data-frame', 'similar', 'names', 'select', 'columns'])\n",
      "('Pandas dataframe to flask template as a json', ['flask', 'template', 'json', 'as', 'a'])\n",
      "('Multiple filter operations on the same dataframe [Pandas]', ['[pandas]', 'operations', 'filter', 'same', 'multiple'])\n",
      "('Label Binarizer: Multiple Columns', ['binarizer:', 'label', 'multiple', 'columns', 'showing'])\n"
     ]
    }
   ],
   "source": [
    "# Structure of your solution to Assignment 1 \n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def analyze_data(filepath):\n",
    "    \n",
    "    data = pd.read_csv(filepath)\n",
    "\n",
    "    print(data[data[\"answercount\"]>=1].sort_values(by=\"viewcount\", ascending=False).iloc[0:3])\n",
    "    print(data[\"quest_name\"].value_counts().iloc[0:5])\n",
    "    data[\"first_tag\"]=data[\"tags\"].apply(lambda x: x.split(\", \")[0])\n",
    "    print(data[data[\"first_tag\"].isin([\"python\",\"pandas\",\"dataframe\"])].groupby(\"first_tag\")[\"viewcount\"].agg([np.min, np.max, np.mean]))\n",
    "    print(pd.crosstab(index=data.answercount, columns=data.first_tag)[\"python\"].loc[0:3])\n",
    "    \n",
    "def analyze_tf_idf(arr,K):\n",
    "    \n",
    "    tf=(arr.T)/1.0*(np.sum(arr, axis=1))\n",
    "\n",
    "    # get df\n",
    "    df=np.sum(np.where(tf>0, 1, 0), axis=1)\n",
    "\n",
    "    # get tf_idf\n",
    "    tf_idf=(tf.T)/(np.log(df)+1)\n",
    "\n",
    "    #return index of top_3 words\n",
    "    top_k=np.argsort(tf_idf)[:,::-1][:,0:K]\n",
    "    \n",
    "    return tf_idf, top_k\n",
    "\n",
    "\n",
    "def analyze_corpus(filepath):\n",
    "    \n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    doc_tokens={}\n",
    "    for idx, doc in enumerate(data[\"title\"].values):\n",
    "        tokens= doc.lower().split()\n",
    "        token_count={w:tokens.count(w) for w in set(tokens)}\n",
    "        doc_tokens[idx]=token_count\n",
    "    \n",
    "    doc_df=pd.DataFrame.from_dict(doc_tokens, orient=\"index\")\n",
    "    doc_df= doc_df.fillna(0)\n",
    "    \n",
    "    tf_idf, top_k=analyze_tf_idf(doc_df.values, 5)\n",
    "    \n",
    "    for i in range(20):\n",
    "        print(data.iloc[i][\"title\"], [doc_df.columns[j] for j in top_k[i]])\n",
    "   \n",
    "\n",
    "\n",
    "# best practice to test your class\n",
    "# if your script is exported as a module,\n",
    "# the following part is ignored\n",
    "# this is equivalent to main() in Java\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Question 1\n",
    "    arr=np.array([[0,1,0,2,0,1],[1,0,1,1,2,0],[0,0,2,0,0,1]])\n",
    "    \n",
    "    print(\"\\nQ1\")\n",
    "    tf_idf, top_k=analyze_tf_idf(arr,3)\n",
    "    print(top_k)\n",
    "    \n",
    "    print(\"\\nQ2\")\n",
    "    print(analyze_data('../../dataset/question.csv'))\n",
    "    \n",
    "    # test question 3\n",
    "    print(\"\\nQ3\")\n",
    "    analyze_corpus('../../dataset/question.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
