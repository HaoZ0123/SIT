{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 1</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define a function to analyze the frequency of words in a string ##\n",
    " - Define a function named \"**tokenize**\" which does the following:\n",
    "     * has a string as an input \n",
    "     * splits the string into a list of tokens by space. For example, \"it's hello world!\" will be split into two tokens [\"it's\", \"hello\",\"world!\"]\n",
    "     * removes all spaces around each token (including tabs, newline characters (\"\\n\"))\n",
    "     * if a token starts with or ends with a punctuation, remove the punctuation, e.g. \"world<font color=\"red\">!</font>\" -> \"world\",  \"<font color=\"red\">'</font>hello<font color=\"red\">'</font>\"->\"hello\" (<font color=\"blue\">hint, you can use *string.punctuation* to get a list of punctuations, where *string* is a module you can import</font>)\n",
    "     * removes empty tokens, i.e. *len*(token)==0\n",
    "     * converts all tokens into lower case\n",
    "     * returns all the tokens as a list output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a class to analyze a document ##\n",
    " - Define a new class called \"**Text_Analyzer**\" which does the following :\n",
    "    - has two attributes: \n",
    "        * **input_string**, which receives the string value passed by users when creating an object of this class.\n",
    "        * **token_count**, which is set to {} when an object of this class is created.\n",
    "        \n",
    "    - a function named \"**analyze**\" that does the following:\n",
    "      * calls the function \"tokenize\" to get a list of tokens. \n",
    "      * creates a dictionary containing the count of every unique token, e.g. {'it': 5, 'hello':1,...}\n",
    "      * saves this dictionary to the token_count attribute\n",
    "    - a function named \"**topN**\" that returns the top N words by frequency\n",
    "      * has a integer parameter *N*  \n",
    "      * returns the top *N* words and their counts as a list of tuples, e.g. [(\"hello\", 5), (\"world\", 4),...] (<font color=\"blue\">hint: By default, a dictionary is sorted by key. However, you need to sort the token_count dictionary by value</font>)\n",
    "  \n",
    "- What kind of words usually have high frequency? Write your analysis.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. (Bonus) Create Bigrams from a document ##\n",
    "\n",
    "A bigram is any pair of consecutive tokens in a document. Phrases are usually bigrams. Let's design a function to find phrases.\n",
    " - Create a new function called \"**bigram**\" which does the following :\n",
    "     * takes a **string** and an integer **N** as inputs\n",
    "     * calls the function \"tokenize\" to get a list of tokens for the input string\n",
    "     * slice the list to get any two consecutive tokens as a bigram. For example [\"it's\", \"hello\",\"world\"] will generate two bigrams: [[\"it's\", \"hello\"],[\"hello\",\"world\"]]\n",
    "     * count the frequency of each unique bigram\n",
    "     * return top N bigrams and their counts \n",
    " - Are you able to find good phrases from the top N bigrams? Write down your analysis in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Guideline##\n",
    "- Following the solution template provided below. Use __main__ block to test your functions and class\n",
    "- Save your code into a python file (e.g. assign1.py) that can be run in a python 3 environment. In Jupyter Notebook, you can export notebook as .py file in menu \"File->Download as\".\n",
    "- Make sure you have all import statements. To test your code, open a command window in your current python working folder, type \"python assign1.py\" to see if it can run successfully.\n",
    "- For more details, check assignment submission guideline on Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Structure of your solution to Assignment 1 \n",
    "\n",
    "import csv\n",
    "\n",
    "def tokenize(text):\n",
    "    \n",
    "    tokens=[]\n",
    "    \n",
    "    # add your code\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "class Text_Analyzer(object):\n",
    "    \n",
    "    def __init__(self, text):\n",
    "        \n",
    "        # add your code\n",
    "          \n",
    "    def analyze(self):\n",
    "        \n",
    "        # add your code\n",
    "        \n",
    "    def topN(self, N):\n",
    "        \n",
    "        # add your code\n",
    "\n",
    "def bigram(doc, N):\n",
    "    \n",
    "    result=[]\n",
    "   \n",
    "    \n",
    "    # add your code\n",
    "    \n",
    "    return result\n",
    "\n",
    "# best practice to test your class\n",
    "# if your script is exported as a module,\n",
    "# the following part is ignored\n",
    "# this is equivalent to main() in Java\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Question 1\n",
    "    text=''' There was nothing so VERY remarkable in that; nor did Alice\n",
    "think it so VERY much out of the way to hear the Rabbit say to\n",
    "itself, `Oh dear!  Oh dear!  I shall be late!'  (when she thought\n",
    "it over afterwards, it occurred to her that she ought to have\n",
    "wondered at this, but at the time it all seemed quite natural);\n",
    "but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT-\n",
    "POCKET, and looked at it, and then hurried on, Alice started to\n",
    "her feet, for it flashed across her mind that she had never\n",
    "before seen a rabbit with either a waistcoat-pocket, or a watch to\n",
    "take out of it, and burning with curiosity, she ran across the\n",
    "field after it, and fortunately was just in time to see it pop\n",
    "down a large rabbit-hole under the hedge.\n",
    "'''   \n",
    "    print(tokenize(text))\n",
    "    \n",
    "    \n",
    "    # Test Question 2\n",
    "    analyzer=Text_Analyzer(text)\n",
    "    analyzer.analyze()\n",
    "    analyzer.topN(5)\n",
    "    \n",
    "    #3 Test Question 3\n",
    "    \n",
    "    top_bigrams=bigram(text)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
