{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 6: Clustering and Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll need to use the following dataset:\n",
    "- text_train.json: This file contains a list of documents. It's used for training models\n",
    "- text_test.json: This file contains a list of documents and their ground-truth labels. It's used for testing performance. This file is in the format shown below. Note, each document has a list of labels.\n",
    "You can load these files using json.load()\n",
    "\n",
    "|Text| Labels|\n",
    "|----|-------|\n",
    "|paraglider collides with hot air balloon ... | ['Disaster and Accident', 'Travel & Transportation']|\n",
    "|faa issues fire warning for lithium ... | ['Travel & Transportation'] |\n",
    "| .... |...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: K-Mean Clustering (5 points)\n",
    "\n",
    "Define a function **cluster_kmean()** as follows: (overall 1 point)\n",
    "- Take two file name strings as inputs: $train\\_file$ is the file path of text_train.json, and $test\\_file$ is the file path of text_test.json\n",
    "- Use **KMeans** to cluster documents in $train\\_file$ into 3 clusters by **cosine similarity** (1 point)\n",
    "- Test the clustering model performance using $test\\_file$: (1 point)\n",
    "  * Predict the cluster ID for each document in $test\\_file$.\n",
    "  * Let's only use the **first label** in the ground-truth label list of each test document, e.g. for the first document in the table above, you set the ground_truth label to \"Disaster and Accident\" only.\n",
    "  * Apply **majority vote** rule to dynamically map the predicted cluster IDs to the ground-truth labels in $test\\_file$. **Be sure not to hardcode the mapping** (e.g. write code like {0: \"Disaster and Accident\"}), because a  cluster may corrspond to a different topic in each run. (1 point)\n",
    "  * Calculate **precision/recall/f-score** for each label (1 point. The f1 score must be above 70%)\n",
    "- This function has no return. Print out confusion matrix, precision/recall/f-score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: LDA Clustering (5 points)\n",
    "\n",
    "Define a function **cluster_lda()** as follows: \n",
    "- Take two file name strings as inputs: $train\\_file$ is the file path of text_train.json, and $test\\_file$ is the file path of text_test.json\n",
    "- Use **LDA** to train a topic model with documents in $train\\_file$ and the number of topics $K$ = 3  (1 point)\n",
    "- Predict the topic distribution of each document in  $test\\_file$, and select **only the topic with highest probability** as the predicted topic (1 point)\n",
    "- Evaluates the topic model performance as follows:\n",
    "  * Similar to Q1, let's use the **first label** in the label list of $test\\_file$ as the ground_truth label.\n",
    "  * Apply **majority vote rule** to map the topics to the labels. (1 point)\n",
    "  * Calculate **precision/recall/f-score** for each label and print out precision/recall/f-score. (1 point; must be above 70%)\n",
    "- Return topic distribution and the original ground-truth labels of each document in $test\\_file$ \n",
    "- Also, provide a document which contains: (1 point)\n",
    "  - performance comparison between Q1 and Q2\n",
    "  - describe how you tune the model parameters, e.g. min_df, alpha, max_iter etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (Bonus): Overlapping Clustering (3 points)\n",
    "\n",
    "In Q2, you predict one label for each document in $test\\_file$. In this question, try to discover multiple labels if appropriate. Define a function **overlapping_cluster** as follows:\n",
    "- Take the outputs of Q2 (i.e. topic distribution and the labels of each document in $test\\_file$) as inputs\n",
    "- Set a threshold for each topic (i.e. $TH = [th_0, th_1, th_2]$). A document is predicted to belong to a topic $i$ only if the topic probability > $th_i$ for $i\\in[0,1,2]$. (1 point)\n",
    "- The threshold is determined as follows:\n",
    "  * Vary the threshold for each topic from 0.05 to 0.95 with an increase of 0.05 in each round to evalute the topic model performance:\n",
    "      * Apply **majority vote rule** to map the predicted topics to the ground-truth labels in $test\\_file$ (1 point)\n",
    "      * Calculate **f1-score** for each label\n",
    "  * For each label, pick the threshold value which maximizes the f1-score (1 point)\n",
    "- Return the threshold and f1-score of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import json, time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_kmean(train_file, test_file):\n",
    "    train=json.load(open(train_file,'r'))\n",
    "    test=json.load(open(test_file,'r'))\n",
    "    test_text, labels = zip(*test)\n",
    "    first_label=[item[0] for item in labels]\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\",\\\n",
    "                             min_df=5) \n",
    "    dtm_train= tfidf_vect.fit_transform(train)\n",
    "    dtm_test= tfidf_vect.transform(test_text)\n",
    "    \n",
    "    num_clusters=3\n",
    "\n",
    "    clusterer = KMeansClusterer(num_clusters, \\\n",
    "                            cosine_distance, \\\n",
    "                            repeats=20)\n",
    "\n",
    "    clusters = clusterer.cluster(dtm_train.toarray(), \\\n",
    "                             assign_clusters=True)\n",
    "    \n",
    "    predict = [clusterer.classify(v) for v in dtm_test.toarray()]\n",
    "    \n",
    "    df=pd.DataFrame(list(zip(first_label, predict)), \\\n",
    "                columns=['actual_class','cluster'])\n",
    " \n",
    "    confusion = pd.crosstab( index=df.cluster, columns=df.actual_class)\n",
    "    print(confusion)\n",
    "    \n",
    "    mapping = confusion.idxmax(axis=1)\n",
    "    for idx, t in enumerate(mapping):\n",
    "        print(\"Cluster {}: Topic {}\".format(idx, t))\n",
    "    \n",
    "    predicted_target=[mapping[i] for i in predict]\n",
    "\n",
    "    print(metrics.classification_report(first_label, predicted_target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_lda(train_file, test_file):\n",
    "    train=json.load(open(train_file,'r'))\n",
    "    test=json.load(open(test_file,'r'))\n",
    "    test_text, labels=zip(*test)\n",
    "    first_label=[item[0] for item in labels]\n",
    "    \n",
    "    tfidf_vect = CountVectorizer(min_df=5, stop_words='english')\n",
    "    \n",
    "    dtm_train= tfidf_vect.fit_transform(train)\n",
    "    dtm_test= tfidf_vect.transform(test_text)\n",
    " \n",
    "    num_clusters=3\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=num_clusters, learning_method='batch',\\\n",
    "                                max_iter=25,verbose=1, n_jobs=1,\n",
    "                                random_state=0).fit(dtm_train)\n",
    "    \n",
    "    topic_assign=lda.transform(dtm_test)\n",
    "    \n",
    "    predict=topic_assign.argmax(axis=1)\n",
    "    \n",
    "    df=pd.DataFrame(list(zip(first_label, predict)), \\\n",
    "                columns=['actual_class','cluster'])\n",
    "\n",
    "    confusion = pd.crosstab( index=df.cluster, \\\n",
    "                            columns=df.actual_class)\n",
    "    print(confusion.head())\n",
    "    mapping = confusion.idxmax(axis=1)\n",
    "    for idx, t in enumerate(mapping):\n",
    "        print(\"Cluster {}: Topic {}\".format(idx, t))\n",
    "    \n",
    "    predicted_target=[mapping[i] for i in predict]\n",
    "\n",
    "    print(metrics.classification_report(first_label, \\\n",
    "                                        predicted_target))\n",
    "\n",
    "    return topic_assign, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def overlapping_cluster(topic_assign, labels):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    Y=mlb.fit_transform(labels)\n",
    "    result = []\n",
    "    cluster_ids = list(range(topic_assign.shape[1]))\n",
    "    for thresh in np.arange(0.05, 1, 0.05):\n",
    "        predict=np.where(topic_assign>thresh, 1, 0)\n",
    "        mapping={}\n",
    "        df = pd.DataFrame(np.hstack([Y, predict]), \\\n",
    "                          columns=mlb.classes_.tolist()+cluster_ids)\n",
    "        df.head()\n",
    "        for l in mlb.classes_:\n",
    "            # majority vote\n",
    "            mapping[l] = df[df[l]==1][cluster_ids].sum(axis=0).idxmax()\n",
    "            \n",
    "        #print(mapping)\n",
    "        \n",
    "        # reorder the predicted to be consistent with truth \n",
    "        predict_reordered=predict[:, [mapping[l] for l in mapping]]\n",
    "        f1 = metrics.f1_score(Y, predict_reordered, average=None)\n",
    "        result.append((thresh, f1))\n",
    "        \n",
    "    thresh, f1 = zip(*result)\n",
    "    thresh_df = pd.DataFrame(list(f1), columns = mlb.classes_, \\\n",
    "                             index = list(thresh))\n",
    "    \n",
    "    #print(thresh_df)\n",
    "    \n",
    "    final_thresh = thresh_df.idxmax(axis = 0)\n",
    "    f1 = thresh_df.max(axis = 0)\n",
    "    #print(final_thresh, f1)\n",
    "    \n",
    "    return final_thresh, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                                70                 0                      135\n",
      "1                               130                 7                        8\n",
      "2                                10               199                       41\n",
      "Cluster 0: Topic Travel & Transportation\n",
      "Cluster 1: Topic Disaster and Accident\n",
      "Cluster 2: Topic News and Economy\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.90      0.62      0.73       210\n",
      "       News and Economy       0.80      0.97      0.87       206\n",
      "Travel & Transportation       0.66      0.73      0.69       184\n",
      "\n",
      "              micro avg       0.77      0.77      0.77       600\n",
      "              macro avg       0.78      0.77      0.77       600\n",
      "           weighted avg       0.79      0.77      0.77       600\n",
      "\n",
      "iteration: 1 of max_iter: 25\n",
      "iteration: 2 of max_iter: 25\n",
      "iteration: 3 of max_iter: 25\n",
      "iteration: 4 of max_iter: 25\n",
      "iteration: 5 of max_iter: 25\n",
      "iteration: 6 of max_iter: 25\n",
      "iteration: 7 of max_iter: 25\n",
      "iteration: 8 of max_iter: 25\n",
      "iteration: 9 of max_iter: 25\n",
      "iteration: 10 of max_iter: 25\n",
      "iteration: 11 of max_iter: 25\n",
      "iteration: 12 of max_iter: 25\n",
      "iteration: 13 of max_iter: 25\n",
      "iteration: 14 of max_iter: 25\n",
      "iteration: 15 of max_iter: 25\n",
      "iteration: 16 of max_iter: 25\n",
      "iteration: 17 of max_iter: 25\n",
      "iteration: 18 of max_iter: 25\n",
      "iteration: 19 of max_iter: 25\n",
      "iteration: 20 of max_iter: 25\n",
      "iteration: 21 of max_iter: 25\n",
      "iteration: 22 of max_iter: 25\n",
      "iteration: 23 of max_iter: 25\n",
      "iteration: 24 of max_iter: 25\n",
      "iteration: 25 of max_iter: 25\n",
      "actual_class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                                30                18                      138\n",
      "1                                12               182                        8\n",
      "2                               168                 6                       38\n",
      "Cluster 0: Topic Travel & Transportation\n",
      "Cluster 1: Topic News and Economy\n",
      "Cluster 2: Topic Disaster and Accident\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.79      0.80      0.80       210\n",
      "       News and Economy       0.90      0.88      0.89       206\n",
      "Travel & Transportation       0.74      0.75      0.75       184\n",
      "\n",
      "              micro avg       0.81      0.81      0.81       600\n",
      "              macro avg       0.81      0.81      0.81       600\n",
      "           weighted avg       0.81      0.81      0.81       600\n",
      "\n",
      "Disaster and Accident      0.45\n",
      "News and Economy           0.55\n",
      "Travel & Transportation    0.30\n",
      "dtype: float64\n",
      "Disaster and Accident      0.798122\n",
      "News and Economy           0.888889\n",
      "Travel & Transportation    0.773218\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Due to randomness, you won't get the exact result\n",
    "    # as shown here, but your result should be close\n",
    "    # if you tune the parameters carefully\n",
    "    \n",
    "    # Q1\n",
    "    cluster_kmean('../../dataset/train_text.json', \\\n",
    "                  '../../dataset/test_text.json')\n",
    "            \n",
    "    # Q2\n",
    "    topic_assign, labels =cluster_lda('../../dataset/train_text.json', \\\n",
    "                          '../../dataset/test_text.json')\n",
    "    \n",
    "    # Q2\n",
    "    threshold, f1 = overlapping_cluster(topic_assign, labels)\n",
    "    print(threshold)\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
