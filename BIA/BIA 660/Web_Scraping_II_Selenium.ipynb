{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Web Scraping II -- Dyamic Web Page Scraping with Selenium </center>\n",
    "\n",
    "References:\n",
    "- http://selenium-python.readthedocs.io/getting-started.html\n",
    "- https://medium.com/the-andela-way/introduction-to-web-scraping-using-selenium-7ec377a8cf72\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Why Selenium\n",
    "- So far, we have learned how to scrape **static** HTML pages using **Requests + BeautifulSoup**\n",
    "- However, if the web content rely on **javascript or AJAX** to build the content, this combination does not work\n",
    "  - Elements in a web page loaded **asynchronously**\n",
    "     * while requests.get(url) can only return the initial content\n",
    "     * you may need to wait for a while to get web content fully loaded\n",
    "  - You need to **interact with the page** to get some content loaded, e.g.\n",
    "     * scroll down to load more\n",
    "     * click a button like \"more\"\n",
    "     * fill a form\n",
    "- Example: 'https://www.quora.com/topic/Machine-Learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1.1. Scape quora page using requests+beautifulsoup\n",
    "\n",
    "# import requests package\n",
    "import requests                   \n",
    "\n",
    "# import BeautifulSoup from package bs4 (i.e. beautifulsoup4)\n",
    "from bs4 import BeautifulSoup   \n",
    "\n",
    "page = requests.get(\"https://www.quora.com/topic/Machine-Learning\")    # send a get request to the web page\n",
    "\n",
    "if page.status_code==200:      \n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # get all questions\n",
    "    questions=soup.select(\"a.question_link span.ui_qtext_rendered_qtext\")\n",
    "    \n",
    "    for i, q in enumerate(questions):\n",
    "        print(i, q.get_text())\n",
    "        print(\"\\n\")\n",
    "    \n",
    "# how many questions are returned? \n",
    "# If you scroll down, more questions are loaded in the browser\n",
    "# but these questions can't be captured "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selenium WebDriver\n",
    "- Selenium WebDriver is one of the most popular tools for **Web UI Automation**\n",
    "- Installation:\n",
    "  - Install Selenium package: \n",
    "    - pip install selenium\n",
    "  - Download a webdirver based on your browser\n",
    "    - Chrome:\thttps://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "    - Firefox:\thttps://github.com/mozilla/geckodriver/releases\n",
    "    - Safari:\thttps://webkit.org/blog/6900/webdriver-support-in-safari-10/\n",
    "  - Here we use **Firefox**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use of Selenium WebDriver\n",
    "\n",
    "### 3.1. **Navigating** (similar to beautifulsoup, but using different syntax)\n",
    "  * navigate to a link\n",
    "  * find elements by id, name, xpath, CSS selectors\n",
    "    * check this for detailed syntax: https://seleniumhq.github.io/selenium/docs/api/py/webdriver_remote/selenium.webdriver.remote.webelement.html\n",
    "  \n",
    "|    | requests/BeautifulSoup | Selenium WebDriver |\n",
    "| -- |:------------------      |:-----------|\n",
    "| Navigate to a link |   requests.get(url)           | driver.get(url)    |\n",
    "| find elements  | soup.find_all() <br> soup.select() | driver.find_element_by_id()<br> driver.find_element_by_tag_name() <br> find_element_by_css_selector(), <br> ...|\n",
    "| get attributes of <br>element (say *p*) | p.attrs <br>    p[\"class\"] | p.get_attribute(\"class\") |\n",
    "| get tag name | p.name | p.tag_name |\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.1.1 Scrape using Selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions \n",
    "\n",
    "# Path where you save the webdriver \n",
    "executable_path = 'driver/geckodriver'\n",
    "\n",
    "# initiator the webdriver for Firefox browser\n",
    "driver = webdriver.Firefox(executable_path=executable_path)\n",
    "\n",
    "# send a request\n",
    "driver.get('https://www.quora.com/topic/Machine-Learning')\n",
    "\n",
    "# you should see a Firefox window open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.1.2. Select truncated text using Selenium\n",
    "\n",
    "# get all questions using css selector\n",
    "questions=driver.\\\n",
    "   find_elements_by_css_selector(\"a.question_link \\\n",
    "   span.ui_qtext_rendered_qtext\")\n",
    "    \n",
    "for i, q in enumerate(questions):\n",
    "    print(i, q.text)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# close the webdriver. The firefox window closes\n",
    "driver.quit()\n",
    "\n",
    "# Note that only questions in the current screen are captured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Simulates users' actions performed in a web browser. \n",
    "\n",
    "  - click a button\n",
    "    * e.g. submit_button.click()\n",
    "  - fill a form\n",
    "    * e.g. text_box.send_keys(\"enter some text\")\n",
    "  - scroll page down or up\n",
    "    * e.g. body.send_keys(Keys.PAGE_DOWN)\n",
    "  - move between windows and frames\n",
    "    * e.g. driver.switch_to_frame(\"frameName\")\n",
    "  ...\n",
    "  - For details see https://selenium-python.readthedocs.io/navigating.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.1 Simulate \"click\"\n",
    "# Click \"more\" link to get full answer\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=executable_path)\n",
    "\n",
    "\n",
    "driver.implicitly_wait(20)\n",
    "\n",
    "driver.get('https://www.quora.com/topic/Machine-Learning')\n",
    "\n",
    "# locate a \"more\" link by css selector\n",
    "more_link=driver.\\\n",
    "find_element_by_css_selector(\"a.ui_qtext_more_link\")\n",
    "\n",
    "# click the link element\n",
    "more_link.click()\n",
    "\n",
    "# Check firefox browser to see an expanded answer\n",
    "\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Wait\n",
    "  - Because of the use of AJAX technologies, web elements often load at different time intervals. \n",
    "  - This makes locating elements difficult. \n",
    "    - if an element is not loaded,  a locating function will raise an ElementNotVisibleException exception.\n",
    "  - Two types of waits \n",
    "    - **implicit**: When a Webdriver locates for any element, but the element is not available, instead of throwing \"No Such Element Exception\" immediately, the Webdriver waits for a certain amount of time. By the time it is still not available, then the error is thrown. \n",
    "      * Implicit wait is set at the driver level and applies to any locating function\n",
    "    - **explicit**: WebDriver waits for a certain condition to occur before proceeding further with execution\n",
    "      * Explicit wait is set at each locating function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.1 Implicit Wait\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=executable_path)\n",
    "\n",
    "# set implicit wait for 10 seconds\n",
    "# Any time, the webdriver is locating an element,\n",
    "# it will wait for at max. 10 seconds \n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# send a request\n",
    "driver.get('https://www.quora.com/topic/Machine-Learning')\n",
    "\n",
    "# find the body element so we can do page down on body\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "\n",
    "# Simulate page down\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "# note that without line 11, you may get an error immediately\n",
    "# With line 10, the webdriver waits \n",
    "# if the element cannot be loaded after 10 seconds\n",
    "# you get an error\n",
    "\n",
    "q=driver.find_element_by_css_selector('a[href=\"/Does-data-science-need-statistics\"]')\n",
    "print(q.text)\n",
    "\n",
    "\n",
    "#driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit Wait\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=executable_path)\n",
    "\n",
    "# send a request\n",
    "driver.get('https://www.quora.com/topic/Machine-Learning')\n",
    "\n",
    "body = driver.find_element_by_css_selector('body')\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "# WebDriver will wait for at max. 10 seconds\n",
    "# to allow the element becomes present\n",
    "# if the element does not show up in 10 seconds\n",
    "# show an error \n",
    "q = WebDriverWait(driver, 10).until(\\\n",
    "          expected_conditions.presence_of_element_located(\n",
    "              (By.CSS_SELECTOR, 'a[href=\"/Does-data-science-need-statistics\"]')))\n",
    "\n",
    "print(q.text)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Example: Pull all Q&As until the end of the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4.1. Get all Q&A pairs\n",
    "\n",
    "import time\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=executable_path)\n",
    "driver.get('https://www.quora.com/topic/Machine-Learning')\n",
    "\n",
    "# keep scroll down to the bottom of the window\n",
    "# check the page source in each scroll-down\n",
    "# if page source is not updated any more\n",
    "# stop \n",
    "\n",
    "\n",
    "src_updated = driver.page_source\n",
    "src = \"\"\n",
    "\n",
    "while src != src_updated:\n",
    "    \n",
    "    # save page source (i.e. html document) before page-down\n",
    "    src = src_updated\n",
    "    \n",
    "    # execute javascript to scroll to the bottom of the window\n",
    "    # you can also use page-down\n",
    "    driver.execute_script(\"window.scrollTo(0, \\\n",
    "    document.body.scrollHeight);\")\n",
    "    \n",
    "    # sleep to allow content loaded\n",
    "    time.sleep(.5)\n",
    "    \n",
    "    # save page source after page-down\n",
    "    src_updated = driver.page_source\n",
    "\n",
    "# list to save Q&A pairs\n",
    "data=[]\n",
    "\n",
    "# get all Q&A list using XPATH locator\n",
    "lists=driver.find_elements_by_xpath(\\\n",
    "            \"//div[@class='paged_list_wrapper']/div\")\n",
    "\n",
    "print(\"total Q&A pairs: \",len(lists))\n",
    "\n",
    "# loop through each div to get details\n",
    "for idx,item in enumerate(lists):\n",
    "    \n",
    "    # each Q&A pair has an unique ID\n",
    "    div_id=item.get_attribute(\"id\")\n",
    "    \n",
    "    # Locate question by the unique ID \n",
    "    question_css=\"div#\"+div_id+\" \"+\"a.question_link span.ui_qtext_rendered_qtext\"\n",
    "    more_link_css=\"div#\"+div_id+\" \"+\"a.ui_qtext_more_link\"\n",
    "    \n",
    "    # Use exception handling in case something wrong\n",
    "    try:\n",
    "        # Find the question link by CSS selector\n",
    "        # This waits up to 10 seconds before throwing a TimeoutException \n",
    "        question=WebDriverWait(driver, 10).until(\\\n",
    "                    expected_conditions.\\\n",
    "             presence_of_element_located((By.CSS_SELECTOR, question_css)))\n",
    "        \n",
    "        \n",
    "        # Get \"more\" link\n",
    "        # however, for some questions, there is no more link\n",
    "        # use exception handling to catch such a situation\n",
    "        try:\n",
    "            # This waits up to 10 seconds before throwing a TimeoutException \n",
    "            # unless it finds the clickable element to return within 10 seconds.\n",
    "            more_link=WebDriverWait(driver, 10).until(\\\n",
    "                    expected_conditions.element_to_be_clickable((By.CSS_SELECTOR, \\\n",
    "                                                                 more_link_css)))\n",
    "            \n",
    "            # click the link\n",
    "            more_link.click()\n",
    "            answer_css=\"div#\"+div_id+\" \"+\"div.ui_qtext_expanded span\"\n",
    "        \n",
    "        except Exception as e: # if \"more\" link is not found\n",
    "            \n",
    "            # get the truncated text by CSS selector\n",
    "            answer_css=\"div#\"+div_id+\" \"+\"div.answer_body_preview span.ui_qtext_rendered_qtext\"\n",
    "   \n",
    "        # Wait for the loading of expanded or (truncated) text located\n",
    "        answer=WebDriverWait(driver, 10).until(\\\n",
    "                    expected_conditions.presence_of_element_located((By.CSS_SELECTOR, answer_css)))\n",
    "        \n",
    "        \n",
    "        # append the question/answer text pairs\n",
    "        data.append((question.text,answer.text ))\n",
    "        \n",
    "    except Exception as e:\n",
    "            print(\"error\")\n",
    "            print(idx,item)\n",
    "        \n",
    "            \n",
    "driver.quit()\n",
    "\n",
    "print(\"Total Q&As scraped: \", len(data))\n",
    "print(\"First Q&A pair\\n\", data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. More about Selenium WebDriver\n",
    "- You can still use BeautifulSoup to parse scraped page source, but BeautifulSoup cannot simulate user interactions\n",
    "- You can also take a snapshot of the Firefox window!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Use beautifulsoup to parse html content retrieved from Selenium WebDriver\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=executable_path)\n",
    "\n",
    "# send a request\n",
    "driver.get('https://www.quora.com/topic/Machine-Learning')\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # get all questions\n",
    "questions=soup.select(\"a.question_link span.ui_qtext_rendered_qtext\")\n",
    "    \n",
    "for i, q in enumerate(questions):\n",
    "    print(i, q.get_text())\n",
    "    print(\"\\n\")\n",
    "        \n",
    "\n",
    "# Take a screenshot\n",
    "driver.save_screenshot('screenshot.png')\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
